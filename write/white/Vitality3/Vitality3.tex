\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}

\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Xspace}{\mathcal{X}}
\newcommand{\Zspace}{\mathcal{Z}}
\newcommand{\Ospace}{\mathcal{O}}
\newcommand{\Sset}{\mathcal{S}}

\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}

\title{Vitality as the Mechanization of Play:\\The Dual Capacities of Dynamic Engagement\\and Symbolic Abstraction\\(Version 3)}
\date{}
\author{}

\begin{document}
\maketitle

\begin{center}
\textit{``The creation of something new is not accomplished by the intellect but by the play instinct acting from inner necessity. The creative mind plays with the objects it loves.'' --- C.G.\ Jung}
\end{center}

\bigskip

\begin{abstract}
We propose Vitality as a formal theory of autonomous development grounded in play.
Play---across species and developmental stages---exhibits two complementary capacities: \textit{dynamic bidirectional engagement} (oscillating between affecting and being affected) and \textit{symbolic abstraction} (operating on meanings and invariants rather than raw percepts).
We formalize the first as Empowerment--Plasticity oscillation (Abel et al.\ 2025) and the second as algebraic constraint learning that extracts discrete, composable, transformation-invariant representations.
Their integration---bidirectional engagement generating disciplined interaction, symbolic abstraction extracting reusable structure that becomes substrate for further engagement---constitutes a developmental loop producing open-ended growth without external rewards.
We present the best available mechanisms for each capacity, then subject them to two structural critiques: entropic objectives cannot be the highest-level goal for autonomy, and the missing symbolic layer creates a self-reinforcing trap with entropy-based methods.
These critiques are not objections to Vitality---they define the research program it points toward.
\end{abstract}

%% ----------------------------------------------------------------
\section{Play}

\subsection{Introduction}

Play appears across species wherever nervous systems support flexible behavior. Piaget demonstrated that play is central to cognitive construction; Trevarthen showed that intersubjective play founds social cognition, explicitly characterizing it through \textit{vitality affects} and \textit{vitality dynamics}---the reciprocal, temporally structured emotional exchanges between infant and caregiver that scaffold all later development; Panksepp identified dedicated neural circuitry for play that cannot be reduced to other motivational systems. Play has structure---it is not random exploration, but rather a specific behavioral regime characterized by two complementary capacities. The term ``vitality'' itself has deep roots in developmental psychology, grounding our formalism in the empirical study of dynamic, reciprocal engagement.

This is not merely a metaphor. When we say play is the mother of all values, we mean it mechanistically: play exhibits a specific architecture---two complementary capacities in a self-sustaining loop---that generates open-ended development without external reward signals. What follows is a mechanization of play---a formal account of its two capacities and the architecture they generate.

\subsection{First Capacity: Dynamic Bidirectional Engagement}

Consider rough-and-tumble play: animals oscillate between influence and receptivity. If one player only pins (pure domination), the game ends. If one player is only pinned (pure submission), the game ends. The game persists if and only if both participants oscillate between affecting and being affected.

We formalize this as two complementary capacities. \textbf{Affecting} (empowerment) is the capacity for actions to reliably influence future observations. \textbf{Being affected} (plasticity) is the capacity for observations to reliably reshape future actions. The pathologies are instructive: pure empowerment leads to rigidity, pure plasticity to puppetry. Play lives where both capacities are simultaneously high and dynamically balanced.

The oscillatory structure is straightforward: perturb the world, observe the result, update your behavior, re-perturb. When this oscillation collapses, the developmental engine stalls.

\subsection{Second Capacity: Symbolic Abstraction}

Consider pretend play: a child picks up a stick and calls it a sword. The operation is abstract the functional role, map it onto a novel substrate, operate on the abstraction. This is symbolic computation in its most basic form: extract structural invariants from experience, recombine them in novel configurations. Piaget called this accommodation leading to assimilation at higher levels.

The symbolic capacity couples naturally to the dynamic capacity. Active probing discovers transformation-invariant features. Once extracted, these symbols become new control targets. For example, once a child abstracts ``tool,'' they begin seeking control over tool-use at this higher level of abstraction, not just control over individual graspable objects.

\subsection{The Developmental Loop}

\begin{definition}[Play as Developmental Loop]
Play implements a self-organizing developmental cycle:
\begin{enumerate}[label=(\alph*)]
  \item \textbf{Bidirectional engagement} generates disciplined interaction near competence boundary.
  \item \textbf{Symbolic abstraction} extracts reusable, transformation-invariant, composable features.
  \item \textbf{Projection}: symbols become new E--P substrates---agent oscillates at higher abstraction level.
  \item \textbf{Repeat}.
\end{enumerate}
Result: open-ended growth without external rewards or hand-designed curricula.
\end{definition}

\subsection{The Dual-Dual Structure}

The two capacities generate a dual-dual architecture. The first duality is dialectical: E and P are mutually regulating opposites whose oscillation constitutes the developmental dynamic. The second is the dual-laws model (Ohmura et al.): feedback error is independently reducible at two levels: by changing weights or executing actions at the base level, or by changing the mathematical structure of the equations themselves---augmenting the relationships between the indices---at the supervenience level. Together these produce a natural three-layer phenomenology.

\subsubsection*{Super-Conscious: The E--P Dialectic}

The bidirectional engagement layer. Empowerment and plasticity co-regulate each other as a Turing-style oscillator---the pre-symbolic drive that selects what is worth attending to and generates the developmental dynamic. This is the first duality: E without P is rigidity, P without E is dissolution, and the system lives in their oscillation. In phenomenal terms this is the true self which sits behind all action and perception---the difference which makes a difference, the silent watcher, the gentle gardener and the slave driver, the seat of the soul---it lives at the level of causation. This is the mercurial hermaphrodite, the true will to power, the cosmic child, the \textit{coincidentia oppositorum}, the \textit{prima materia} and the goal of its own transformation---of every living thing.

\subsubsection*{Conscious: The Symbolic Index Layer}

The supervenience level in the dual-laws model. Already-learned representations are \textbf{selected, composed, and recombined} here via an \textit{index sequence}---a discrete ordering of representational indices. Each index selects a particular structured description of the world, and the sequence determines which descriptions are active and how they combine. This selection is influenced by the E--P dynamics from above, by external environmental inputs from below via associative triggering, and potentially through social mediation as in \textbf{\textit{Cybernetic Mimesis}}. The core point is that a \textbf{competitive dynamics} lives at this layer---it decides which index of the learned perceptual features interprets perceptual input and which control objectives govern action---this is schema selection for action and perception. Modifying the index sequence is Type~2 processing: discrete, exploratory, symbolic---the agent manipulates \textit{which representations to deploy}, not how to learn or execute them. Since Type~2 is inherently discrete, it plausibly becomes advanced in organisms with sophisticated linguistic capacities---language itself being an index system. There is no reason to think Type~2 is uniquely human, but its elaboration likely tracks the capacity for discrete symbolic recombination.

\subsubsection*{Sub-Conscious: The Neuronal Dynamics Layer}

The base level. This layer changes to satisfy the constraints generated by the higher layer, either through \textbf{learning} (algebraic constraint learning lives here) or through \textbf{behavior} (feedback control and reflexes). This is Type~1 processing: continuous, goal-directed, subsymbolic. It encompasses the embodied dynamics of the agent--world coupling: motor control, proprioception, sensorimotor loops---the physics of interaction through which all higher-level structure must ultimately be realized. Crucially, through execution and reflexes this layer generates the interaction data from which new representations will be extracted, feeding back up to the conscious and super-conscious layers. The sub-conscious is both the executor and the data source---it enacts the schemas selected above and, in doing so, produces the raw material from which further schemas are learned.

\subsection{Klopf's Critique and the Nature of Autonomy}

Klopf (1982) observed that classical cybernetics---Wiener, Ashby---built a science of homeostasis, negative feedback toward set-points. But living systems are also self-amplifying: they seek stimulation, escalate challenges, pursue novelty. Klopf called this \textit{heterostasis}, the drive toward more rather than back to baseline. Sepulchre (2022) showed that robust adaptive systems require both positive and negative feedback coupled together. Negative feedback alone converges to a fixed point. Positive feedback alone explodes. Development, learning, and play all require both, coupled.

This brings us to the notion of autonomy underlying Vitality. Autonomy is not just homeostasis, and not just heterostasis. It is both, coupled, in the same system.

\begin{definition}[Autonomy]
Autonomy = self-regulation + self-amplification. If the system has only internal constraint, the environment supplies all the drives; if it has only internal drive, the environment supplies all the limits. Only when both are internally generated does the system itself become a genuine source of causation rather than a channel for external forces.
\end{definition}

This definition distinguishes autonomy from viability. Viability is purely negative feedback---self-regulation without self-amplification. A thermostat is viable. It maintains a set-point through reactive correction, but it does not generate its own movement. Viability requires external perturbation to produce behavior. An organism can be viable (persist as a coherent entity through homeostatic regulation) without being autonomous in the sense we mean here.

Genuine autonomy requires the E--P oscillator. When empowerment and plasticity are coupled as a dynamical system, that coupled system is autonomous. E regulates P (influencing the world shapes what can reconfigure you), and P regulates E (reconfigurability sustains influence in non-stationary environments). The oscillator self-regulates through this bidirectional coupling. Simultaneously, E and P mutually amplify each other: expanded empowerment generates richer feedback for plasticity, and expanded plasticity enables more sophisticated empowerment. The E--P engine generates its own developmental dynamics. It does not wait for perturbation---it produces self-generated movement.

Vitality is this autonomous regime. The E--P oscillator sustains itself through bidirectional co-regulation. $V_t$ measures the strength of this regime, but vitality itself is the pattern of E--P co-regulation, not the score. Viability keeps you alive. Vitality makes you autonomous.

The convergence is striking. Sepulchre's control-across-scales work demands this dual structure. Klopf diagnosed its absence in cybernetics. Play provides it naturally: a regime where self-regulation and self-amplification are co-constitutive.

%% ----------------------------------------------------------------
\section{Vitality: Formalizing Play}

\subsection{Setup}

We work with an agent whose state space $\Xspace$ is partitioned into internal state $Y_t$ and world state $W_t$. The agent interacts through an interface $\lambda$ consisting of actions $A_{1:T}$ and observations $O_{1:T}$. Policies $\pi$ induce trajectory distributions over this joint space.

\subsection{Formalizing Bidirectional Engagement}

\begin{definition}[Empowerment]
\[
  E_t(\lambda) := I(A \leadsto O;\, \lambda)_t
\]
Channel capacity for actions to influence future observations.
\end{definition}

\begin{definition}[Plasticity]
\[
  P_t(\lambda) := I(O \leadsto A;\, \lambda)_t
\]
Channel capacity for observations to reshape future actions.
\end{definition}

\begin{proposition}[Abel Tradeoff]
$E_t + P_t \leq m_t(\lambda)$, where $m_t(\lambda)$ is interface-dependent upper bound.
\end{proposition}

\textbf{Vitality as Co-Regulatory Regime.} Vitality is the Turing-esque dynamical pattern where empowerment and plasticity co-regulate each other: E regulates P (influencing the world shapes what reconfigures you), P regulates E (reconfigurability sustains influence in non-stationary environments). This is a specific behavioral regime, not just a number.

\begin{definition}[Vitality Measure (time-local)]
\[
  V_t(\lambda) := \frac{2\,E_t\, P_t}{E_t + P_t}
\]
This harmonic mean measures the strength of the co-regulatory regime at time $t$. It requires both E and P positive, penalizes extremes, and reaches maximum when $E_t = P_t$.
\end{definition}

\subsection{Temporal Morphogens}

\begin{definition}[Internalization]
Interface capacities (fast measurements) internalized as slow state:
\[
  \Ecal_{t+1} = (1 - \alpha_E)\Ecal_t + \alpha_E\, E_t(\lambda), \qquad
  \Pcal_{t+1} = (1 - \alpha_P)\Pcal_t + \alpha_P\, P_t(\lambda)
\]
\end{definition}

Here $\Ecal_t$ is a slow ``skill/commitment'' morphogen and $\Pcal_t$ is a slow ``reconfigurability'' morphogen.

\textbf{Knowledge as self-persisting information.} The morphogens are not merely statistics about past interaction---they are \textit{knowledge} in the constructionist sense. Following Piaget's insight that knowledge is not stored data but self-maintaining structure, we recognize that $\Ecal_t$ and $\Pcal_t$ are the agent's consolidated developmental history, actively maintaining themselves through the E--P loop. They persist not because they are written to memory, but because they regulate the very interactions that regenerate them. This is knowledge as self-persisting information: the morphogens ARE what the agent has learned, and they persist precisely because they shape how the agent continues to engage with the world.

\textbf{Structure.} The morphogens modulate the fast loop: adaptation strength is proportional to $f(\Pcal_t)$ while stability and precision are proportional to $g(\Ecal_t)$. This creates a reaction--diffusion structure where $\Ecal$ acts as activator (stabilizing) and $\Pcal$ acts as inhibitor (destabilizing). The different timescales---$\alpha_P \ll \alpha_E$, making plasticity slow to recruit but fast to act---produce temporal Turing patterns: alternating plateau phases (exploit, high $\Ecal$, low $\Pcal$) and burst phases (explore, recruited $\Pcal$). Developmental transitions emerge as bifurcations between behavioral regimes.

\subsection{Formalizing Symbolic Abstraction}

Given observations $\{o_t\}$ from interaction, we learn an encoder $\phi: \Ospace \to \Zspace$ mapping into a factored latent space $\Zspace = \Zspace_1 \times \cdots \times \Zspace_k$. The requirements are threefold: (1)~\textbf{group-theoretic decomposition}, where each $\Zspace_i$ transforms independently under a subgroup $G_i$; (2)~\textbf{transformation invariance}, where each factor captures a structural invariant reusable across contexts; and (3)~\textbf{discretizability}, where factors are naturally discretizable (finite groups, discrete orbits), yielding a vocabulary of \textit{perceptual symbols}.

The algebraic structure is central. Each factor $\Zspace_i$ is not an arbitrary latent dimension but a representation space for a transformation group $G_i$. When the world transforms under $g \in G_i$ (rotation, translation, scaling), the corresponding latent factor transforms covariantly: $\phi_i(g \cdot o) = g \cdot \phi_i(o)$. This is equivariance: the representation respects the group action. The constraint learning objective biases the encoder to discover these group structures by factoring the full transformation group into conditionally independent subgroups. The result is a disentangled representation where each factor captures an independent degree of freedom in the world's causal structure.

Discretizability follows naturally from group structure. Finite groups (symmetries of discrete objects) yield finite vocabularies directly. Continuous groups (rotations, translations) discretize via orbit representatives: choose a canonical element from each equivalence class under the group action. For example, rotation-invariant features discretize by selecting canonical orientations, yielding symbols like ``vertical edge'' and ``horizontal edge'' rather than continuous angle values. This is not lossy quantization---it is extraction of the invariant. The symbol ``vertical edge'' is more primitive than ``edge at 87 degrees'' because it is stable under small perturbations and reusable across contexts.

Composability is the final requirement. Symbols must combine productively. If $\Zspace_i$ represents ``shape'' and $\Zspace_j$ represents ``color,'' the product space $\Zspace_i \times \Zspace_j$ represents ``colored shapes,'' and novel combinations (red triangle, blue square) are immediately available without retraining. This combinatorial productivity is what makes symbols different from distributed representations: a new percept involving known symbols is not out-of-distribution, it is a novel combination of known primitives.

\begin{definition}[Symbolic Inventory]
$\Sset_t = \{(\Zspace_i, G_i, \phi_i)\}_{i=1}^{k_t}$ grows over development. Each entry is a factored representation space, its transformation group, and an encoder. The inventory expands as new invariants are discovered.
\end{definition}

\subsection{The Integrated Definition}

\begin{definition}[Vitality (Version 3)]
A system exhibits Vitality over horizon $T$ if it sustains the E--P co-regulatory regime with the following properties:
\begin{enumerate}
  \item \textbf{High dynamic engagement}: $\bar{V}_T$ sustained above threshold, indicating strong bidirectional coupling between empowerment and plasticity.
  \item \textbf{Growing symbolic inventory}: $|\Sset_T| > |\Sset_0|$ (reusable abstractions extracted from the interaction data generated by E--P oscillation).
  \item \textbf{Loop closure}: learned symbols become new E--P substrates, so empowerment--plasticity dynamics shift to operate over symbolic space, not just raw sensorimotor channels.
\end{enumerate}
\end{definition}

The distinguishing feature is condition~(3). This is not simply ``intrinsic motivation + representation learning.'' The loop closes: symbols are recruited into control, which generates new interactions, which extract further abstractions.

\subsection{Pathologies}

\begin{center}
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Pathology} & \textbf{Why excluded} \\
\midrule
Frozen agent & $\Pcal_t \to 0 \Rightarrow V_t \to 0$ (no negative feedback) \\
Rewrite-soup & $\Ecal_t \to 0 \Rightarrow V_t \to 0$ (no positive feedback) \\
Novelty chaser & No symbolic extraction despite exploration \\
Compressor & No bidirectional engagement driving feature selection \\
Static optimizer & No projection of symbols back into E--P---development stops \\
\bottomrule
\end{tabular}
\end{center}

%% ----------------------------------------------------------------
\section{Best Mechanisms We Have}

\subsection{For Bidirectional Engagement}

Abel et al.\ (2025) formalize plasticity as the dual of empowerment within generalized directed information. They define channel capacities in both directions---forward ($A \to O$) and reverse ($O \to A$)---and prove a tight tradeoff: $E + P \leq m(\lambda)$. The interface has finite bidirectional capacity, and any allocation must respect this bound.

Internalizing E and P as slow morphogens yields reaction--diffusion structure. The plateau phase (high $\Ecal$, low $\Pcal$) corresponds to exploitation. The burst phase (recruited $\Pcal$) corresponds to exploration. This maps directly onto the explore--exploit oscillation familiar from reinforcement learning, but here it emerges from the coupled morphogen dynamics rather than being imposed externally. Developmental transitions emerge as bifurcations in this dynamical system.

\subsection{For Symbolic Abstraction}

The algebraic constraint learning framework (Ohmura et al.) provides the theoretical foundation. It biases feature discovery toward group-theoretic decompositions by imposing equivariance constraints during learning. The key insight is that the world's transformations factor into conditionally independent subgroups, and a well-structured representation should mirror this factorization. The learning objective encourages the encoder to discover these subgroups: when a transformation $g$ acts on observations, the encoder should decompose $g$ into independent components acting on separate latent factors. This is not merely disentanglement (statistical independence of latents) but algebraic disentanglement (factorization of the transformation group). The result is features that are operationally meaningful (each factor corresponds to an independent degree of freedom), naturally discretizable (via orbit representatives), and composable (the product structure enables novel combinations).

The implementation challenge is that group structure is not given a priori---it must be discovered from data. The constraint learning framework addresses this by learning both the encoder and the group factorization jointly. The encoder proposes candidate factors, and the factorization objective measures how cleanly transformations decompose across these factors. Features that fail to respect the group structure are penalized. Over development, this produces an inventory of symbols that are not arbitrary latent codes but genuine structural invariants.

Discrete codebook methods provide complementary techniques for enforcing discreteness. VQ-VAE (van den Oord et al.\ 2017) constructs discrete latent representations via vector quantization: the continuous encoder output is mapped to the nearest entry in a learned discrete codebook. This enforces a finite vocabulary while preserving gradient-based learning through the straight-through estimator. Discrete Codebook World Models (Scannell et al.\ 2025) extend this by preserving ordinal relationships: the codebook is structured so that perceptually similar observations map to nearby codebook entries. This combines discreteness (finite vocabulary, combinatorial recombination) with metric structure (similarity is preserved). The result is a symbolic representation that supports both compositional reasoning and smooth generalization.

GFlowNets (Bengio et al.\ 2023) address a different aspect of symbolic abstraction: navigating discrete combinatorial structure. Traditional neural methods struggle with discrete search spaces because gradients do not propagate through discrete choices. GFlowNets treat discrete generation as a stochastic flow, where the probability of constructing an object is proportional to a learned reward. This enables flexible exploration of symbolic spaces---searching over discrete programs, molecular graphs, or compositional symbolic structures---with neural guidance. In the Vitality context, GFlowNets could enable symbolic search over candidate representations: exploring the combinatorial space of factorizations to find structures that maximize $V$.

DreamCoder (Ellis et al.\ 2021) demonstrates how symbolic inventories can grow through use. It bootstraps compositional program libraries through wake-sleep cycles: during the wake phase, the system solves tasks by composing existing primitives; during the sleep phase, it abstracts common patterns into new reusable primitives, which are then added to the library. The library grows over time, and later tasks are solved by composing high-level abstractions rather than low-level operations. This is a computational model of loop closure: symbols extracted from problem-solving (wake) become primitives for future problem-solving (sleep), and the cycle repeats. Its discrete, composable building blocks---programs in a typed lambda calculus---provide a concrete instantiation of what a symbolic inventory looks like when it expands developmentally.

\subsection{For the Integration}

The integration of dynamic engagement with symbolic abstraction is the core novelty. Current representation learning and intrinsic motivation frameworks fail because they address one side without the other. Representation learning produces features without knowing which are behaviorally useful. Intrinsic motivation explores without extracting reusable abstractions. Neither closes the developmental loop. Vitality integrates them: E--P selects which features matter, features become new E--P substrates, and the cycle repeats. This section makes the integration mechanism explicit.

\subsubsection{E--P as Selection Pressure for Representation Learning}

Representation learning suffers from an underdetermination problem: in unsupervised settings, infinitely many representations compress the data equally well. There is no principled selection criterion beyond reconstruction error or contrastive loss. The result is that learned features may be statistically optimal but behaviorally useless. A representation that perfectly reconstructs pixels might miss the affordances that matter for action. A representation that maximizes mutual information between temporally adjacent frames might encode irrelevant details while ignoring controllable structure.

E--P provides the missing selection pressure. A feature $z$ is valuable if and only if it expands both $E$ (controllability via $z$) and $P$ (sensitivity to $z$). This is a functional criterion: features must support bidirectional coupling. It filters out features that compress well but don't enable better engagement. Concretely, a feature that captures static visual texture (high reconstruction quality) but is uncontrollable (low $E$) will not be selected. A feature that captures a perfectly controllable variable (high $E$) but is insensitive to environmental changes (low $P$) will also be rejected. Only features that enable both influence and responsiveness---bidirectional engagement---are retained.

The formal mechanism is straightforward. At time $t$, the agent has symbolic inventory $\Sset_t = \{z_1, \ldots, z_k\}$. For each symbol $z \in \Sset_t$, compute $E_t(\lambda_z)$ and $P_t(\lambda_z)$---the empowerment and plasticity available when controlling or observing through $z$. Features with high vitality $V_t(\lambda_z) = 2E_t(\lambda_z)P_t(\lambda_z)/(E_t(\lambda_z)+P_t(\lambda_z))$ are retained and elaborated. Features with low $V_t(\lambda_z)$ are pruned or not extracted in the first place. This implements developmental filtering: the dynamic layer shapes what the symbolic layer learns.

The practical implication is that representation learning should be constitutively constrained by E--P expansion. The training objective should not be reconstruction or contrastive prediction alone, but E--P expansion through the learned features. This inverts the standard pipeline: instead of learning representations first and then using them for control, the control objective (bidirectional engagement) shapes representation learning from the start. Features emerge because they expand the agent's capacity for play, not because they compress data efficiently.

\subsubsection{Symbols as New E--P Substrates}

Once extracted, symbols $z \in \Sset_t$ become new control and observation targets. The E--P dynamics shift from sensorimotor space $(A, O)$ to symbolic space $(Z_A, Z_O)$. The agent now seeks to influence and be influenced at the level of abstractions, not raw percepts.

A Piaget-style example clarifies this. At the sensorimotor stage, E--P operates over raw actions (grasp, release) and observations (visual flow, tactile feedback). At the object stage, the agent abstracts ``graspable object,'' and E--P now operates over object-level actions (``grab the cup'') and object-level observations (``cup moved''). At the relational stage, the agent abstracts ``containment,'' and E--P operates over relational actions (``put A in B'') and relational observations (``A is inside B''). Each level's symbols become the substrate for the next level's E--P oscillation.

This closes the loop. Symbols extracted from E--P data at level $n$ become E--P targets at level $n+1$. This is recursive abstraction: the mechanism that generates symbols also consumes them. Contrast this with static representation learning, where features are extracted once and used for downstream tasks but not fed back into the feature-extraction process itself.

\subsubsection{Hierarchical Developmental Dynamics}

The developmental loop does not merely iterate---it builds hierarchical structure. This connects to two foundational frameworks: Powers' Perceptual Control Theory (PCT), which describes behavior as a hierarchy of feedback control loops at increasing levels of abstraction, and Piaget's developmental stages, which document how children construct increasingly abstract operational capacities through interaction.

Powers (1973) proposed that control is hierarchically organized: lower levels control immediate perceptual intensities, while higher levels control relationships, sequences, principles, and systematic goals. Each level sets reference signals for the level below, and each level perceives through the outputs of lower levels. The hierarchy is not imposed externally---it emerges from the recursive composition of control loops. Piaget (1952, 1954) documented the developmental progression empirically: sensorimotor intelligence grounds in direct causal interaction, preoperational thought introduces symbolic representation, concrete operations enable reversible transformations and conservation, and formal operations abstract over operations themselves.

E--P plus symbolic abstraction mechanizes this progression. The ground floor is causal. At the sensorimotor level, E--P oscillates over raw actions (reach, grasp, push) and observations (visual motion, tactile contact, proprioceptive feedback). The agent probes: \textit{when I push here, what happens?} High E--P engagement generates rich interaction data exhibiting causal structure. This is Powers' intensity and sensation control: the most basic feedback loops, closing through the physics of the body-world coupling. Algebraic constraint learning extracts transformation-invariant features from this data: ``graspable object,'' ``containment,'' ``occlusion.'' These are not arbitrary compressions---they are features that expand $V$ by enabling finer control (empowerment) and richer response (plasticity).

Once ``object'' is extracted, it becomes a new control target. The conscious layer's index sequences reconfigure to address objects as units. The E--P dynamics shift upward: the agent no longer seeks to control raw visual flow, but to control objects as persistent, manipulable entities. High-$V$ regions now involve object-level interactions: ``retrieve occluded object,'' ``stack blocks.'' This is Piaget's transition from sensorimotor to preoperational intelligence, and Powers' transition to configuration and transition control. The data generated at this level exhibits relational structure. The constraint learner extracts ``containment,'' ``support,'' ``behind/in-front'' as the next symbolic layer.

At the relational level, E--P operates over relations. The agent seeks to control \textit{which relations hold}: ``make A contain B,'' ``put C on top of D.'' This generates data exhibiting compositional structure: relations compose (A on B, B on C implies A above C). The constraint learner extracts transformation rules: commutativity, associativity, conservation. These are Piaget's concrete operations and Powers' relationship and category control.

At the formal level, E--P operates over transformation rules themselves. The agent seeks to control \textit{which operations are valid}: ``find the set of moves that solves this puzzle,'' ``construct a proof.'' This generates data exhibiting algebraic structure: groups, morphisms, equivalence classes. The constraint learner extracts metasymbolic features: ``symmetry,'' ``invariance,'' ``homomorphism.''

Each transition is driven by the same mechanism: E--P oscillation at level $\ell$ generates interaction data, algebraic constraint learning extracts symbols $\Sset_{\ell+1}$ that are transformation-invariant at level $\ell$, and these symbols become new control targets at level $\ell+1$. The hierarchy is not hand-designed. It emerges because symbols extracted from causal interaction are inherently compositional, and composition generates structure that itself becomes worth controlling.

The key insight is that new control levels are not pre-wired but emerge through E--P-driven abstraction. This produces an emergent curriculum: the agent naturally explores near its competence boundary---the region where $V$ is high but not yet saturated. High-$V$ regions become new training grounds. Developmental transitions are bifurcations in the coupled E--P--symbolic system: as new symbols are recruited, the dynamics qualitatively shift to operate at a higher level. No external curriculum is needed---the loop generates its own scaffolding.

\begin{proposition}[Integration as Core Novelty]
Neither intrinsic motivation alone (empowerment without symbolic extraction) nor representation learning alone (symbolic extraction without intrinsic selection pressure) produces open-ended development. The integration---E--P selects features, features become new E--P substrates---closes the developmental loop.
\end{proposition}

%% ----------------------------------------------------------------
\section{Problems with These Mechanisms}

The mechanisms in Section~3 are the best we have. They are also structurally limited in ways that define the research agenda.

\subsection{The Entropic Problem}

E and P are mutual information quantities. $V_t$ inherits every limitation of information-theoretic optimization. These are not engineering complaints---they are theorem-level structural limitations.

\textbf{Problem 1: Representation presupposition (Shannon 1949).} Computing $I(A \leadsto O)$ requires well-defined random variables and probability spaces. But choosing the right variables is the hard problem. Shannon explicitly excluded semantics from information theory. The consequence is that information theory assumes the representation problem is already solved. V3's algebraic learner partially addresses this by providing variables, but the bootstrap remains: initial E--P must operate over raw sensorimotor variables whose structure is assumed.

\textbf{Problem 2: Intractability (McAllester \& Stratos 2020, Theorem~1).} Any distribution-free lower bound on MI estimated from $N$ samples cannot be larger than $O(\ln N)$. The number of samples required is exponential in the true MI. For small discrete codebooks this softens (finite sums, Blahut-Arimoto becomes tractable), but $n$-step empowerment scales as $|A|^n$, and compositional state spaces explode combinatorially. This is a proven limitation, not a solvable optimization problem.

\textbf{Problem 3: Structural poverty.} Entropy collapses all structure into a scalar. It cannot distinguish algebraic from topological from causal constraints. $V_t = 2EP/(E+P)$ is a single number, blind to the compositional structure of $\Sset_t$ that it supposedly governs. The harmonic mean does not know about the group theory of the symbolic inventory.

\textbf{Problem 4: Causal blindness (Bareinboim et al.\ 2022, Causal Hierarchy Theorem).} Mutual information is symmetric by definition: $I(X;Y) = I(Y;X)$. But causation is directional. The Causal Hierarchy Theorem states that observational data underdetermines interventional and counterfactual quantities. E and P are Layer~1 (associational)---they can be inflated by confounders and distributional drift. Genuine influence and sensitivity require interventional structure, which MI does not capture.

\subsection{The Self-Reinforcing Trap}

The trap has two exits, both blocked. Without symbols, you are stuck with entropy---your only objectives are statistical. Without non-entropic objectives, there is no pressure to learn symbols---continuous approximations are always locally sufficient. The subsymbolic-entropic paradigm is self-reinforcing: it defines both representation and objective in terms that exclude the structures that would reveal its limits.

V3 attacks both exits. E--P provides the dynamics, algebraic constraints provide the symbols. But the tension between the entropic core (E and P are mutual information) and the algebraic periphery ($\Sset_t$ has non-entropic structure) remains unresolved. The harmonic mean does not know about the group theory. This is not a bug. It points toward what must be built next.

%% ----------------------------------------------------------------
\section{What Needs to Be Done}

The problems in Section~4 are real and foundational, not engineering complaints. Here is what must be built.

\subsection{A Causal, Computationally Tractable Bidirectional Intrinsic Motivation}

E--P gets the structure right: bidirectional, oscillatory, self-regulating plus self-amplifying. But the current realization in mutual information is both causally blind and intractable at scale.

The requirements for a successor are clear. It must be causal: grounded in interventional quantities ($P(O|\text{do}(A))$ not $P(O|A)$), so that influence and sensitivity are genuine rather than confounded. And it must be computationally tractable: not requiring exponential samples or variational bounds that change qualitative behavior.

A promising direction is Gunji and Pegios, ``Natural-Born Intelligence as the Invocation of Emotion = Politics,'' which connects bidirectional engagement to non-information-theoretic quantities that might sidestep the MI trap entirely.

\subsection{Representation Learning That Does Both Indexing and Feature Extraction}

The requirements are twofold: the system must index the world into discrete, addressable, manipulable symbols (codebook or vocabulary construction), and it must extract features that are transformation-invariant and algebraically structured (not just compressed statistics).

Current methods fail at the intersection. VQ-VAE indexes but doesn't extract algebraic structure. Ohmura's algebraic constraints extract structure but don't produce an indexed vocabulary. What's needed is a system that builds a discrete inventory of structurally meaningful features, where the indexing and the structure are the same thing.

\subsection{Integration: Representation Learning Constrained by the Mother-of-All-Values Intrinsic Motivation}

This is the deepest open problem. The dynamic engagement component---E--P, or its causal successor---should function as a higher-order constraint on representation learning, not just supplying selection pressure for features but determining what kind of representations are worth having in the first place.

Intrinsic motivation is the mother of all values, the master landscape that all representation learning descends into. Features are valuable not because they compress data, not because they reconstruct observations, but because they expand the agent's capacity for bidirectional engagement with the world.

Representation learning should be constitutively constrained by E--P expansion. The objective for feature extraction should not be reconstruction or contrastive prediction, but E--P expansion itself. The symbolic and dynamic components are not just coupled---they are aspects of a single process. The agent simultaneously learns what to attend to and how to engage with what it attends to.

%% ----------------------------------------------------------------

\begin{thebibliography}{99}

\bibitem{abel2025} Abel, D., et al.\ (2025). Plasticity as the Mirror of Empowerment. \textit{arXiv:2505.10361}.

\bibitem{ay2008} Ay, N.\ \& Polani, D.\ (2008). Information Flows in Causal Networks. \textit{Advances in Complex Systems}, 11(1).

\bibitem{bareinboim2022} Bareinboim, E., et al.\ (2022). On Pearl's Hierarchy and the Foundations of Causal Inference. \textit{ACM Books}.

\bibitem{bengio2023} Bengio, E., et al.\ (2023). GFlowNet Foundations. \textit{JMLR}, 24.

\bibitem{ellis2021} Ellis, K., et al.\ (2021). DreamCoder. \textit{PLDI}.

\bibitem{gunji} Gunji, Y.-P.\ \& Pegios, A.\ Natural-Born Intelligence as the Invocation of Emotion = Politics.

\bibitem{klopf1982} Klopf, A.H.\ (1982). \textit{The Hedonistic Neuron: A Theory of Memory, Learning, and Intelligence}. Hemisphere.

\bibitem{mcallester2020} McAllester, D.\ \& Stratos, K.\ (2020). Formal Limitations on the Measurement of Mutual Information. \textit{AISTATS}.

\bibitem{ohmura} Ohmura, Y., et al.\ Algebraic Structural Feedback Control and Genetic Epistemology.

\bibitem{panksepp1998} Panksepp, J.\ (1998). \textit{Affective Neuroscience}. Oxford University Press.

\bibitem{pearl2009} Pearl, J.\ (2009). \textit{Causality} (2nd ed.). Cambridge University Press.

\bibitem{piaget1952} Piaget, J.\ (1952). \textit{The Origins of Intelligence in Children}. International Universities Press.

\bibitem{piaget1954} Piaget, J.\ (1954). \textit{The Construction of Reality in the Child}. Basic Books.

\bibitem{powers1973} Powers, W.T.\ (1973). \textit{Behavior: The Control of Perception}. Aldine.

\bibitem{scannell2025} Scannell, A., et al.\ (2025). Discrete Codebook World Models. \textit{ICLR}.

\bibitem{sepulchre2022} Sepulchre, R.\ (2022). Control Across Scales. \textit{Annual Review of Control, Robotics, and Autonomous Systems}.

\bibitem{trevarthen1979} Trevarthen, C.\ (1979). Communication and Cooperation in Early Infancy. In \textit{Before Speech}. Cambridge University Press.

\bibitem{vqvae2017} van den Oord, A., et al.\ (2017). Neural Discrete Representation Learning. \textit{NeurIPS}.

\end{thebibliography}

\end{document}
